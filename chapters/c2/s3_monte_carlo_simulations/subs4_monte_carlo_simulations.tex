\subsubsection{Monte Carlo Simulations}

Monte Carlo methods (MCMs), the commonly used computational techniques, aim to generate samples from a given probability distribution, estimate the functions' expectations under this distribution, and optimize the complicated objective functions by using random numbers \cite{kroese2014monte}. MCMs can be used to solve the IBVPs by generating the random numbers to simulate the successive positions of the trajectory of a stochastic process at fixed instants \cite{kronberg1976solution}\cite{king1951monte}, since the original continuous problem can be represented by the probabilistic interpretation and the solution can be approximated by the expectation of some functional of the trajectories of a stochastic process \cite{grebenkov2014efficient}\cite{sabelfeld2013random}. Therefore, unlike the numerical techniques proposed in the subsubsection~\ref{numerical methods}, the nondeterministic Monte Carlo simulations are grid-free on the domain, boundary, and the boundary conditions of the problem \cite{grebenkov2014efficient}.


Monte Carlo simulations have been applied frequently in solving the elliptic partial differential equation, for example, the Laplace’s and Poisson’s equations \cite{haji1967application} \cite{booth1981exact} \cite{muller1956some}. For example, let $u(P_0)$ be the value of the solution of the elliptic partial differential equation at a specific point $P_0$ in a bounded domain. $u(P_0)$ can be estimated by a point $P_1$, which is sampled uniformly on the largest circle $C_0$ centered at $P_0$ with radius $r_0$ lying entirely in the domain. If $P_1$ gets closed to the target bounday within an error, $u(P_1)$ is known, and it can be considered as a particle's estimate of $u(P_0)$ by multiplying the particle’s statistical weight. If not, $u(P_1)$ is should be estimated in the same way as $u(P_0)$, that is, $P_2$ is sampled uniformly on the largest circle $C_1$ centered at $P_1$ with radius $r_1$ lying entirely in the domain. Check the position of $P_2$, and the procedure will be repeated until the simulation is terminates on the traget boundary, which is defined as one particle's estimate of $u(P_0)$. Finally, averaging a larger number of one-particle estimates, $u(P_0)$ will be more accurate. 


However, Monte Carlo simulations are barely applied in solving parabolic and hyperbolic partial differential equations, such as the $1-$ dimensional and $2-$ dimensional time-dependent heat problem. As introduced in the paper \cite{sadiku2006monte}, after obtaining the probabilistic interpretation of the finit-difference approximation of the heat equation using the central-space and backward-time scheme, the solution of the heat equation at a specific space-time point can be approximated by averaging a large number of random-walking particles, whose trajectories are modeled by the Monte Carlo methods untill they hit the any sites of the target boundary. However, the drawbacks of this method are obvious. Firstly, there is the error appeared in the finit-difference approximation. Secondly, there has the statistical sampling errors inherent in the Monte Carlo simulations. Thirdly, this method can only be used to approximate the solution of the heat equation at one point at a time. Last but not least, it is more direct to simulate the random walks by the Monte Carlo simulations for solving the heat equation rather than to firstly introduce the finite-difference approximation. 







